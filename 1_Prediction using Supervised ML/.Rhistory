m <- matrix( c(1,2,3,4),2,2 )
apply(m, 1, sum)
m
apply(m, 2, sum)
list <- list(c(1,1, b=c(2,2, c=c(3,3)))
list <- list(c(1,1, b=c(2,2, c=c(3,3))))
list <- list(c(1,1, b=c(2,2, c=c(3,3))
lapply(list, sum)
list <- list(c(1,1, b=c(2,2, c=c(3,3))))
lapply(list, sum)
lapply(list, mean)
# sapply()
list <- list(a=c(1,1), b=c(2,2), c=(3,3))
# sapply()
list <- list(a=c(1,1), b=c(2,2), c=c(3,3))
sapply(list, sum)
sapply(list, range)
lapply(list, sum)
# Importing the dataset
dataset = read.csv('D:\\R machine learning\\Machine Learning A_Z_sets\\Part 2 - Regression\\Section 4 - Simple Linear Regression\\R\\Salary_Data.csv')
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
str(dataset)
str(training_set)
str(test_set)
dim(training_set)
View(training_set)
View(test_set)
# Fitting Simple Linear Regression to the Training set
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set)
summary(regressor)
# Predicting the Test set results
y_pred = predict(regressor, newdata = test_set)
summary(y_pred)
# Visualising the Training set results
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
library(ggplot2)
ggplot() +
geom_point(aes(x = test_set$YearsExperience, y = test_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
test_set$reven_pred <- predict(regressor, newdata = testSet)
# Importing the dataset
dataset = read.csv('D:\\R machine learning\\Machine Learning A_Z_sets\\Part 2 - Regression\\Section 5 - Multiple Linear Regression\\R\\50_Startups.csv')
# Encoding categorical data
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1, 2, 3))
View(dataset)
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Fitting Multiple Linear Regression to the Training set
regressor = lm(formula = Profit ~ .,
data = training_set)
# Predicting the Test set results
y_pred = predict(regressor, newdata = test_set)
summary(y_pred)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Marketing.Spend + Administration + State,
data = dataset)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Marketing.Spend + Administration,
data = dataset)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Marketing.Spend + Administration,
data = training_set)
summary(regressor)
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
# Importing the dataset
dataset = read.csv('D:\\R machine learning\\Machine Learning A_Z_sets\\Part 2 - Regression\\Section 7 - Support Vector Regression (SVR)\\R\\Position_Salaries.csv')
dataset = dataset[2:3]
# Fitting SVR to the dataset
# install.packages('e1071')
library(e1071)
regressor = svm(formula = Salary ~ .,
data = dataset,
type = 'eps-regression',
kernel = 'radial')
# Predicting a new result
y_pred = predict(regressor, data.frame(Level = 6.5))
# Visualising the SVR results
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(regressor, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (SVR)') +
xlab('Level') +
ylab('Salary')
# Visualising the SVR results (for higher resolution and smoother curve)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (SVR)') +
xlab('Level') +
ylab('Salary')
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(regressor, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (SVR)') +
xlab('Level') +
ylab('Salary')
# Visualising the SVR results (for higher resolution and smoother curve)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (SVR)') +
xlab('Level') +
ylab('Salary')
dataset = read.csv('C:\\Users\\user\\Downloads\\tests.csv')
dataset2 = read.csv('C:\\Users\\user\\Downloads\\attempts.csv')
str(dataset)
str(dataset2)
View(dataset)
View(dataset2)
dataset3 <- dataset2[!duplicated(dataset2$attempt_id), ]
str(dataset3)
dataset3 <- dataset2$attempt_id[!duplicated(dataset2$attempt_id), ]
str(dataset3)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(corrplot)
dataset <- read.csv('SampleSuperstore.csv')
setwd(choose.dir())
dataset <- read.csv('SampleSuperstore.csv')
### Explore the data of the retail store
glimpse(dataset)
# Count the number of missing data if any
lapply(lapply(dataset, is.na), sum)
cat('There are', count(dataset[duplicated(dataset), ])[1,1], 'duplicate values to be removed. Done.')
dataset <- dataset[!duplicated(dataset), ]
### Which states are most profitable?
profit_by_state <- dataset %>%
group_by(State) %>%
select(State, Profit) %>%
summarise(Profit = sum(Profit)) %>%
arrange(desc(Profit))
# Simple Bar Plot comparing the Total profit of the store per state
ggplot(data=profit_by_state, aes(x=State, y=Profit, fill=time)) +
geom_bar(colour="black", fill="#DD8888", width=.8, stat="identity") +
guides(fill='none') +
xlab("States") + ylab("Profit") +
ggtitle("Total Profit per State") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
### How are the features correlated?
corrplot(cor(dataset[, c(10,11,12,13)]), method = "color", outline = T, cl.pos = 'n', rect.col = "black",
tl.col = "indianred4", addCoef.col = "black",
number.digits = 2, number.cex = 0.60, tl.cex = 0.7, cl.cex = 1,
col = colorRampPalette(c("green4","white","red"))(100))
### Is there a certain threshold before discounts affect profit negatively?
profit_by_discount <- dataset %>%
group_by(Discount) %>%
select(Discount, Profit) %>%
summarise(Profit = sum(Profit)) %>%
arrange(Discount)
# Bar Plot comparing the total profit according to the discount given
barplot(profit_by_discount$Profit ~ profit_by_discount$Discount,
main="Relationship Between Profit and Discount",
xlab="Discount margin",
ylab="Profit")
table(dataset[dataset$Discount > 0.2,][,5])
### Which Category has the highest sales? Profits?
sales_by_category <- dataset %>%
group_by(Category) %>%
select(Category, Sales, Profit) %>%
summarise(Sales = sum(Sales), Profit = sum(Profit)) %>%
arrange(desc(Sales))
# Simple Bar Plot
ggplot(data=sales_by_category, aes(x=Category, y=Sales, fill=time)) +
geom_bar(colour="black", fill="#DD8888", width=.8, stat="identity") +
guides(fill='none') +
xlab("States") + ylab("Profit") +
ggtitle("Total Profit per State") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
### Whats the overall discount distribution for each category? Its impact on sales and profit?
unique(dataset$Category)
data_furniture <- dataset[,c(8,10,11,12,13)]
data_furniture$Category <- factor(data_furniture$Category)
grid.arrange(ggplot(data_furniture, aes(x=Discount, y=Sales, shape=Category, color=Category)) +
geom_point() + ggtitle('Discount vs Sales for Each Category'),
ggplot(data_furniture, aes(x=Discount, y=Profit, shape=Category, color=Category)) +
geom_point() + ggtitle('Discount vs Profit for Each Category'),nrow=2)
# The number of items in each category
table(data_furniture$Category)
### The details should be explored further.
# A bar plot is used to illustrate the quantity difference between the categories.
ggplot(data=dataset, aes(x=Category, y=Quantity, fill=time)) +
geom_bar(colour="black", fill="#DD8888", width=.8, stat="identity") +
guides(fill='none') +
xlab("Category") + ylab("Quantity") +
ggtitle("Quantity of Items Sold per Category") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
# This leaves the question of how discounts ranges affect the overall supply profitability.
dev.off()
Office_sup_df <- data.frame(Quantity_low_Discount = sum(data_furniture$Quantity[data_furniture$Discount<=0.6 & data_furniture$Category=='Office Supplies']),
Profit_low_Discount = sum(data_furniture$Profit[data_furniture$Discount<=0.6 & data_furniture$Category=='Office Supplies']),
Quantity_high_Discount = sum(data_furniture$Quantity[data_furniture$Discount>0.6 & data_furniture$Category=='Office Supplies']),
Profit_high_Discount = sum(data_furniture$Profit[data_furniture$Discount>0.6 & data_furniture$Category=='Office Supplies']))
# Set up the work directory and read the file
setwd(choose.dir())
# Set up the work directory and read the file
setwd(choose.dir())
predict(regressor, newdata = 9.5)
df = read.csv('student_scores.csv')
# Check its dimension, type of variables and number of observations
str(df)
# Check for empty rows
df[df=='NA']
# Plot the table to visualize it
library(ggplot2)
ggplot() +
geom_point(aes(x = df$Hours, y = df$Score), colour = 'red') +
ggtitle('X vs Y (Training set)') +
xlab('No_SalesMan') +
ylab('Revenue')
# Splitting the dataset
library(caTools)
set.seed(19800)
split = sample.split(df$Score, SplitRatio = 0.7)
training_set = subset(df, split == T)
test_set = subset(df, split = F)
# Feature scaling is not necessary due to having 2 variables only.
# Fitting the linear regression to the training set
regressor = lm(formula = Scores ~ ., data = training_set)
# The intercepts are as follows
regressor
# Predicting the test set results
y_predict = predict(regressor, newdata = test_set)
summary(y_predict)
# Visualize the predicted scores vs the actual scores
# The line shows the predicted values
ggplot() +
geom_point(aes(x = df$Hours, y = df$Score),
colour = 'red') +
geom_line(aes(x = test_set$Hours, y = predict(regressor, newdata = df)),
colour = 'blue') +
ggtitle('Sleep Hours vs Score') +
xlab('Hours') +
ylab('Score')
predict(regressor, newdata = 9.5)
predict(regressor, data.frame(9.25))
predict(regressor, data.frame(Hours = 9.25))
